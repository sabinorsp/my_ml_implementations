{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9a6e8e",
   "metadata": {},
   "source": [
    "   # Implementação algoritmo Rede Neural Artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8725045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7b76136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parameters = {} # Dicionário para os parâmetros\n",
    "        self.learning_rate = 0\n",
    "        self.nums_iterations = 0\n",
    "        \n",
    "        \n",
    "    # Função para Inicialização randômica dos parametros do modelo\n",
    "    def inicializa_parametros(self,dims_camada_entrada):\n",
    "        \"\"\"\n",
    "        Inicializa parametros aleatórios para os pesos.\n",
    "        \n",
    "        Arg:\n",
    "            dims_camada_entrada (list): [total de variáveis, nº neuronio camada 1, \n",
    "                                         nº neuronio camada 2,\n",
    "                                         ..., \n",
    "                                         nº neuronio camada n,\n",
    "                                         ]\n",
    "        Retorna: \n",
    "            dict: dicionário com os valores iniciais dos pesos para cada camada do neurônio.\n",
    "            \n",
    "        \"\"\"\n",
    "        # Comprimento das dimensões das camadas, quantidade de camadas da rede\n",
    "        comp = len(dims_camada_entrada)\n",
    "        for i in range(1, comp):\n",
    "            # Inicialização da matriz de pesos\n",
    "            self.parameters[\"W\" + str(i)] = np.random.randn(dims_camada_entrada[i], dims_camada_entrada[i - 1]) * 0.01\n",
    "            # Inicialização do bias\n",
    "            self.parameters[\"b\" + str(i)] = np.zeros((dims_camada_entrada[i], 1))\n",
    "        return self.parameters\n",
    "    \n",
    "    \n",
    "    # Função sigmóide: utilizada para ativação da ultima camada\n",
    "    @staticmethod\n",
    "    def sigmoid(Z):\n",
    "        \"\"\"\n",
    "        Converte qualquer valor real de Z para valores no intervalo de 0 e 1.\n",
    "        \n",
    "        Args:\n",
    "            Z (float): qualquer número pertencente ao conjunto dos nº reais.\n",
    "        \n",
    "        Retorna:\n",
    "            tupla : contendo o valor transformado pela função e o próprio valor de entrada\n",
    "        \"\"\"\n",
    "        A = 1 / (1 + np.exp(-Z))\n",
    "        return A, Z\n",
    "    \n",
    "    \n",
    "    # Função de ativação ReLu (Rectified Linear Unit): Ativação camadas intermediárias\n",
    "    @staticmethod\n",
    "    def relu(Z):\n",
    "        \"\"\"\n",
    "        Converte qualquer valor real de Z para 0 quando Z menor que 0,\n",
    "        e retorna a imagem de Z para valores maiores que 0. \n",
    "        \n",
    "        Args:\n",
    "            Z (float): qualquer número pertencete ao conjunto dos nº reais\n",
    "        \n",
    "        Retorna:\n",
    "            tupla: \n",
    "        \"\"\"\n",
    "        A = abs(Z * (Z > 0))\n",
    "        return A, Z\n",
    "    \n",
    "    \n",
    "    # Ativação linear\n",
    "    def linear_activation(A, W, b):\n",
    "        \"\"\"\n",
    "        Realiza a operação de ativação por camada\n",
    "        \n",
    "        Args: \n",
    "            A (numpy.ndarray): matriz com os dados de entrada da camada\n",
    "            W (numpy.ndarray): matriz de pesos da camada\n",
    "            b (numpy.ndarray): bias\n",
    "        \n",
    "        Retorna:\n",
    "            tupla: contendo o valor de ativação e das memórias das matrizes dos pesos. \n",
    "        \"\"\"\n",
    "        Z = np.dot(W, A) + b\n",
    "        cache = (A, W, b)\n",
    "        return Z, cache\n",
    "    \n",
    "    \n",
    "    # Forward Propagation\n",
    "    # Movimento para frente (forward)\n",
    "    def forward(A_prev, W, b, activation):\n",
    "        \"\"\"\n",
    "        Aplica a função de ativação nos resultados da multiplcaçãdo dos dados pelos coeficientes\n",
    "        \n",
    "        Args: \n",
    "            A_prev (numpy.ndarray): Dados entrada prévios;\n",
    "            W (numpy.ndarray): Matriz de coeficientes da camada;\n",
    "            b (numpy.ndarray): bias da camada;\n",
    "            activation (str): tipo da função de ativação \"sigmoid\" ou \"relu\"\n",
    "        \n",
    "        Retorna:\n",
    "            tupla: A: os resultados dos valores passado pela função de ativação;\n",
    "                   cache: mémoria dos dados iniciais, matriz de coeficiente e bias\n",
    "        \"\"\"\n",
    "\n",
    "        # Se a função de ativação for Sigmoid, entramos neste bloco\n",
    "        if activation == \"sigmoid\":\n",
    "            Z, linear_cache = linear_activation(A_prev, W, b)\n",
    "            A, activation_cache = sigmoid(Z)\n",
    "\n",
    "        # Se não, se for ReLu, entramos neste bloco    \n",
    "        elif activation == \"relu\":\n",
    "            Z, linear_cache = linear_activation(A_prev, W, b)\n",
    "            A, activation_cache = relu(Z)\n",
    "\n",
    "        cache = (linear_cache, activation_cache)\n",
    "\n",
    "        return A, cache\n",
    "\n",
    "    \n",
    "    # Propagação para frente\n",
    "    def forward_propagation(X, parameters):\n",
    "        \"\"\"\n",
    "        Realiza as multiplicações de matrizes de cada camada da rede.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy.ndarray): Valores dos dados de treinamento;\n",
    "            parameters (dict): dicionario das matrizes de coeficientes e bias\n",
    "        \n",
    "        Retorna:\n",
    "            tupla: A_last -> valores de saida da última camada;\n",
    "                            caches -> lista com os valores calculados nas camadas internas;\n",
    "        \"\"\"\n",
    "        # Lista de valores anteriores (cache)\n",
    "        caches = []\n",
    "        # Dados de entrada\n",
    "        A = X\n",
    "        # Comprimento dos parâmetros\n",
    "        L = len(parameters) // 2\n",
    "        # Loop\n",
    "        for i in range(1, L):\n",
    "            # Guarda o valor prévio de A\n",
    "            A_prev = A\n",
    "            # Executa o forward\n",
    "            A, cache = forward(A_prev, parameters[\"W\" + str(i)], parameters[\"b\" + str(i)], activation = \"relu\")\n",
    "            # Grava o cache\n",
    "            caches.append(cache)\n",
    "        # Saída na última camada\n",
    "        A_last, cache = forward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], activation = \"sigmoid\")\n",
    "        # Grava o cache\n",
    "        caches.append(cache)\n",
    "        return(A_last, caches)\n",
    "    \n",
    "    \n",
    "    # Função de custo (ou função de erro)\n",
    "    def calcula_custo(A_last, Y):\n",
    "        \"\"\"\n",
    "        Calcula a função custo dado a comparação de valores previstos e valores de treinamento reais\n",
    "        \n",
    "        Args: \n",
    "            A_last (numpy.ndarray): Matriz da última camada contendo as estimativas do modelo.\n",
    "            Y (numpy.ndarray): valores reais dos dados de treinamento\n",
    "        \n",
    "        Retorna: \n",
    "            numpy.ndarray: valor da função custo\n",
    "        \"\"\"\n",
    "        # Ajusta o shape de Y para obter seu comprimento (total de elementos)\n",
    "        m = Y.shape[1]\n",
    "        # Calcula o custo comparando valor real e previso (função logit para custo)\n",
    "        custo = (-1 / m) * np.sum((Y * np.log(A_last)) + ((1 - Y) * np.log(1 - A_last)))\n",
    "        # Ajusta o shape do custo\n",
    "        custo = np.squeeze(custo)\n",
    "        return(custo)\n",
    "    \n",
    "\n",
    "    ## == BackPropagation == ##\n",
    "    # Função sigmoid para o backpropagation ( Derivada da função sigmoid)\n",
    "    def sigmoid_backward(da, Z):\n",
    "        \"\"\"\n",
    "        Calcula a derivada da função de ativação sigmoid, sua taxa de variação.\n",
    "        \n",
    "        Args:\n",
    "            da (float): derivada da previsão final da rede (feita ao final do Forward Propagation).\n",
    "            Z (float): valores da multiplicação dos pesos pelos dados da camada.\n",
    "        \n",
    "        Retorna: \n",
    "            float: taxa de variação da função sigmoid.\n",
    "        \"\"\"\n",
    "        # Calculamos a derivada de Z\n",
    "        dg = (1 / (1 + np.exp(-Z))) * (1 - (1 / (1 + np.exp(-Z))))\n",
    "        # Encontramos a mudança na derivada de z\n",
    "        dz = da * dg # regra da cadeia*\n",
    "        return dz\n",
    "    \n",
    "    \n",
    "    # Função relu para o backpropagation \n",
    "    def relu_backward(da, Z):\n",
    "        \"\"\"\n",
    "        Calcula a derivada da função de ativação relu\n",
    "        \n",
    "        Args: \n",
    "            da (float): derivada da previsão final da rede (feita ao final do Forward Propagation).\n",
    "            Z (float): valores da multiplicação dos pesos pelos dados da camada.\n",
    "            \n",
    "        Retorna: \n",
    "            float: taxa de variação da função relu.\n",
    "        \"\"\"\n",
    "        dg = 1 * ( Z >= 0)\n",
    "        dz = da * dg # regra da cadeia*\n",
    "        return dz\n",
    "    \n",
    "    \n",
    "    # Ativação linear para o backpropagation\n",
    "    def linear_backward_function(dz, cache):\n",
    "        \"\"\"\n",
    "        Calcula as derivadas da operação backward propragation\n",
    "        \n",
    "        Args: \n",
    "            dz (float): taxa de variação da função de ativação\n",
    "            cache (tupla): (linear_cache, activation_cache) \n",
    "                            linear_cache -> resultado da multiplicação dos pesos pelos dados da camada.\n",
    "                            activation_cache -> resultado da função de ativação dado o linear_cache como entrada.\n",
    "        \n",
    "        Retorna: \n",
    "            tupla: derivada da operação (W*dz), derivada da matriz peso W (dz*A_prev), derivada do bias.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Recebe os valores do cache (memória)\n",
    "        A_prev, W, b = cache\n",
    "        # Shape de m\n",
    "        m = A_prev.shape[1]\n",
    "        # Calcula a derivada de W (resultado da operação com dz)\n",
    "        dW = (1 / m) * np.dot(dz, A_prev.T)\n",
    "        # Calcula a derivada de b (resultado da operação com dz)\n",
    "        db = (1 / m) * np.sum(dz, axis = 1, keepdims = True)\n",
    "        # Calcula a derivada da operação\n",
    "        dA_prev = np.dot(W.T, dz)\n",
    "        return dA_prev, dW, db\n",
    "\n",
    "\n",
    "    def linear_activation_backward(dA, cache, activation):\n",
    "        \"\"\"\n",
    "        Define o tipo de ativação ( relu ou sigmoid)\n",
    "        \n",
    "        Args:\n",
    "            dA: derivada da previsão final da rede (feita ao final do Forward Propagation)\n",
    "            cache: cache mémoria dos dados iniciais, matriz de coeficiente e bias\n",
    "            activation: Define a função de ativação \"relu\" ou \"sigmoid\"\n",
    "        \n",
    "        Retorna:\n",
    "            tupla: derivada da operação (W*dz), derivada da matriz peso W (dz*A_prev), derivada do bias.\n",
    "        \"\"\"\n",
    "        # Extrai o cache\n",
    "        linear_cache, activation_cache = cache\n",
    "        # Verifica se a ativação é relu\n",
    "        if activation == \"relu\":\n",
    "            dZ = relu_backward(dA, activation_cache)\n",
    "            dA_prev, dW, db = linear_backward_function(dZ, linear_cache)\n",
    "        # Verifica se a ativação é sigmoid\n",
    "        if activation == \"sigmoid\":\n",
    "            dZ = sigmoid_backward(dA, activation_cache)\n",
    "            dA_prev, dW, db = linear_backward_function(dZ, linear_cache)\n",
    "        return dA_prev, dW, db\n",
    "\n",
    "\n",
    "    def backward_propagation(AL, Y, caches):\n",
    "        \"\"\"\n",
    "        Calcula os gradientes para atualização dos pesos\n",
    "        \n",
    "        Args:\n",
    "            AL (numpy.ndarray): matriz das previsões realizadas pelo foward.\n",
    "            Y (numpy.ndarray): matriz dos resultados reais.\n",
    "            caches (list): lista com os valores calculados nas camadas internas;\n",
    "        \n",
    "        Retorna:\n",
    "            dict: Dicionário contendo os gradientes dos dados, dos pesos e do bias.\n",
    "        \"\"\"\n",
    "        # Dicionário para os gradientes\n",
    "        grads = {}\n",
    "        # Comprimento dos dados (que estão no cache)\n",
    "        L = len(caches)\n",
    "        # Extrai o comprimento para o valor de m\n",
    "        m = AL.shape[1]\n",
    "        # Ajusta o shape de Y\n",
    "        Y = Y.reshape(AL.shape)\n",
    "        # Calcula a derivada da previsão final da rede (feita ao final do Forward Propagation)\n",
    "        dAL = -((Y / AL) - ((1 - Y) / (1 - AL)))\n",
    "        # Captura o valor corrente do cache\n",
    "        current_cache = caches[L - 1]\n",
    "        # Gera a lista de gradiente para os dados, os pesos e o bias\n",
    "        # Fazemos isso uma vez, pois estamos na parte final da rede, iniciando o caminho de volta\n",
    "        grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "        # Loop para calcular a derivada durante as ativações lineares com a relu\n",
    "        for l in reversed(range(L - 1)):\n",
    "            # Cache atual\n",
    "            current_cache = caches[l]\n",
    "            # Calcula as derivadas\n",
    "            dA_prev, dW, db = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "            # Alimenta os gradientes na lista, usando o índice respectivo\n",
    "            grads[\"dA\" + str(l)] = dA_prev\n",
    "            grads[\"dW\" + str(l + 1)] = dW\n",
    "            grads[\"db\" + str(l + 1)] = db        \n",
    "        return grads\n",
    "\n",
    "    \n",
    "    # Função de atualização de pesos\n",
    "    def atualiza_pesos(parameters, grads, learning_rate):\n",
    "        \"\"\"\n",
    "        Realiza a atualização dos pesos em cada camada da rede.\n",
    "        \n",
    "        Args:\n",
    "            parameters (dict): dicionário contendo todas matrizes de pesos.\n",
    "            grads (dict): dicionário contendo todas as matrizes dos gradientes calculados. \n",
    "            learning_rate (float): taxa de aprendizado.\n",
    "        \n",
    "        Retorna:\n",
    "            dict: dicionário contendo as matrizes de pesos atualizados pelo gradiente do backpropagation.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Comprimento da estrutura de dados com os parâmetros (pesos e bias)\n",
    "        L = len(parameters)//2\n",
    "        # Loop para atualização dos pesos\n",
    "        for l in range(L):\n",
    "            # Atualização dos pesos\n",
    "            parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - (learning_rate * grads[\"dW\" + str(l + 1)])\n",
    "            # Atualização do bias\n",
    "            parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - (learning_rate * grads[\"db\" + str(l + 1)])\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    # Modelo completo da rede neural\n",
    "    def modeloNN(X, Y, dims_camada_entrada, learning_rate = 0.0075, num_iterations = 100):\n",
    "        \"\"\"\n",
    "        Executa o treinamento do modelo da Rede Neural Artificial.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy.ndarray): Dados treinamento variáveis independentes.\n",
    "            Y (numpy.ndarray): Dados treinamento variáveis dependentes.\n",
    "            dims_camada_entrada: Dimensões das camadas e estruturas de Neurônios.\n",
    "            learning_rate (float): Taxa de apresendizado do modelo.\n",
    "            num_iterations (int): Quantidade de iterações para o treinamento do modelo.\n",
    "            \n",
    "        Retorna: \n",
    "            tupla: dicionário dos parametros treinados, lista dos custos por iteração de treinamento. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Lista para receber o custo a cada época de treinamento\n",
    "        custos = []\n",
    "\n",
    "        # Inicializa os parâmetros\n",
    "        parametros = inicializa_parametros(dims_camada_entrada)\n",
    "\n",
    "        # Loop pelo número de iterações (épocas)\n",
    "        for i in range(num_iterations):\n",
    "\n",
    "            # Etapa Forward Propagation\n",
    "            AL, caches = forward_propagation(X, parametros)\n",
    "\n",
    "            # Calcula o custo\n",
    "            custo = calcula_custo(AL, Y)\n",
    "\n",
    "            # Etapa Backward Propagation (Atualização dos pesos)\n",
    "            # Nota: ao invés de AL e Y, poderíamos passar somente o valor do custo\n",
    "            # Estamos passando o valor de AL e Y para fique claro didaticamente o que está sendo feito\n",
    "            gradientes = backward_propagation(AL, Y, caches)\n",
    "\n",
    "            # Atualiza os pesos\n",
    "            parametros = atualiza_pesos(parametros, gradientes, learning_rate)\n",
    "\n",
    "            # Print do valor intermediário do custo\n",
    "            # A redução do custo indica o aprendizado do modelo\n",
    "            if i % 10 == 0:\n",
    "                print(\"Custo Após \" + str(i) + \" iterações é \" + str(custo))\n",
    "                custos.append(custo)\n",
    "\n",
    "        return parametros, custos\n",
    "    \n",
    "    \n",
    "    # Função para fazer as previsões\n",
    "    # Não precisamos do Backpropagation pois ao fazer previsões como o modelo treinado, \n",
    "    # teremos os melhores valores de pesos (parametros)\n",
    "    def predict(X, parametros):\n",
    "        AL, caches = forward_propagation(X, parametros)\n",
    "        return AL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4608d85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-5.63630455e-04, -9.90960229e-03, -6.92388239e-03, ...,\n",
       "          2.13546958e-03, -5.36667137e-03,  3.82150714e-03],\n",
       "        [-1.13175880e-04, -1.28247133e-02,  4.48982770e-03, ...,\n",
       "          1.66075648e-02, -1.13295415e-02,  3.76920882e-03],\n",
       "        [ 7.88615062e-03,  1.49771723e-02,  1.47014008e-02, ...,\n",
       "         -1.80061007e-03, -9.76798391e-03, -8.62071135e-03],\n",
       "        ...,\n",
       "        [-9.33836051e-03, -1.13140559e-02, -4.98414580e-03, ...,\n",
       "          3.98528031e-03,  5.90763699e-04,  3.29522816e-03],\n",
       "        [-5.91532148e-03,  2.09890397e-02, -2.52679389e-03, ...,\n",
       "          8.89972579e-03, -9.50421771e-03,  2.09793011e-02],\n",
       "        [-1.35372064e-03, -9.41887958e-05, -1.50589675e-02, ...,\n",
       "         -1.03862118e-03,  3.47324125e-03, -1.08791655e-02]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-1.20014307e-02, -9.02560656e-03,  1.48621104e-02,\n",
       "         -8.03994772e-03,  8.39208453e-03, -3.17015857e-03,\n",
       "          4.48476692e-03,  9.84474644e-03, -1.63075824e-02,\n",
       "          4.79054031e-03,  9.30665315e-03,  2.29078355e-02,\n",
       "         -2.25221674e-03,  3.69078688e-03, -1.44393560e-02,\n",
       "          8.95003152e-03, -3.16177129e-03,  5.62393170e-03,\n",
       "          3.88046814e-03, -9.01364752e-03,  1.11652547e-02,\n",
       "          7.08107714e-03, -2.26868754e-03, -3.35117672e-03,\n",
       "          2.10054454e-02,  5.14415597e-03, -1.47330581e-03,\n",
       "          1.78372498e-02,  1.48540910e-02, -4.51575340e-03,\n",
       "          4.61358888e-03,  4.99001699e-03,  1.24495441e-02,\n",
       "          2.28755776e-03,  5.29258364e-03, -1.12270305e-02,\n",
       "         -1.06991559e-02,  6.78529429e-03, -5.12888840e-04,\n",
       "         -1.69036623e-02, -2.29961179e-02,  1.52522021e-02,\n",
       "          2.18867825e-02, -5.31388526e-03,  1.06526523e-02,\n",
       "          6.01220880e-03,  9.99532286e-03, -1.40850214e-02,\n",
       "          1.46642424e-02, -4.84549417e-03],\n",
       "        [ 1.40699217e-03, -4.03497527e-03, -2.40457424e-02,\n",
       "          3.21491392e-03,  2.01265972e-02,  3.36113434e-03,\n",
       "          5.84681610e-04,  9.84710044e-03, -9.31501570e-04,\n",
       "         -1.69051580e-02, -1.08936082e-03,  2.90192765e-03,\n",
       "         -6.07643123e-03,  5.23802499e-03,  1.96483430e-02,\n",
       "         -1.37730082e-02,  4.04911063e-04,  1.94166097e-02,\n",
       "         -2.25130954e-04,  1.01790848e-03,  2.12461766e-03,\n",
       "          9.42203757e-03, -6.63986744e-03, -9.31749385e-03,\n",
       "          7.86084230e-03, -9.38834166e-03,  4.49260302e-03,\n",
       "         -9.60818359e-03, -1.06944404e-02, -7.35490242e-03,\n",
       "         -1.21334703e-03, -4.09674016e-03, -1.52277489e-02,\n",
       "          5.14065196e-03,  1.57357592e-03, -4.08939367e-03,\n",
       "          5.68429621e-03,  6.45396553e-03, -1.60550836e-03,\n",
       "         -3.34912239e-03,  1.21220052e-02,  1.26143329e-02,\n",
       "          8.34803615e-03, -3.45109097e-04,  1.17165884e-03,\n",
       "          3.06363285e-03,  3.50793466e-03,  1.42350338e-02,\n",
       "          1.80884677e-02,  1.07946335e-02],\n",
       "        [-1.52224967e-02, -6.35993560e-04,  1.20856859e-02,\n",
       "          3.51208299e-03,  1.49340673e-02, -3.60081385e-03,\n",
       "         -1.08449434e-02, -4.26457792e-03, -1.04542404e-02,\n",
       "         -2.01144400e-02, -1.89983567e-03,  1.72671918e-02,\n",
       "          1.28410575e-02,  2.35268426e-02,  9.73459498e-03,\n",
       "          3.44477164e-03,  5.20507180e-03,  2.01386600e-02,\n",
       "          2.36610089e-02,  7.61386810e-03, -9.88793275e-03,\n",
       "         -1.26726246e-03, -2.31056949e-03,  1.06439133e-02,\n",
       "         -7.99747581e-04,  2.95194343e-03,  6.82931536e-03,\n",
       "         -6.60653813e-03, -4.06067636e-03,  1.40232707e-02,\n",
       "          4.96749136e-03,  7.06454792e-03, -1.76134569e-04,\n",
       "          1.33817100e-03,  3.57421776e-03, -4.12109600e-03,\n",
       "          6.16664522e-03,  2.54452831e-03,  8.39141673e-04,\n",
       "          1.94369107e-03, -1.89878230e-04,  9.19907206e-03,\n",
       "         -1.75222095e-03, -1.34325490e-02, -4.04789027e-03,\n",
       "         -8.56585959e-03,  1.56635796e-03,  1.15962346e-02,\n",
       "         -8.60077857e-03, -1.17964412e-02],\n",
       "        [-5.22506530e-03,  8.43590559e-03, -6.31339492e-03,\n",
       "          7.87081874e-04, -1.59039505e-04,  3.66994404e-03,\n",
       "         -7.26774862e-04,  1.47616724e-02,  1.60665769e-02,\n",
       "         -5.08387634e-03,  4.14761440e-03, -5.25550712e-03,\n",
       "         -8.80773126e-03,  2.61800702e-03, -5.07591443e-04,\n",
       "          6.16800982e-03,  2.77716223e-03, -1.63006428e-03,\n",
       "          2.07160697e-02, -1.01533887e-02,  5.99186061e-03,\n",
       "         -3.96035624e-03,  9.97666095e-03,  2.31933119e-02,\n",
       "          5.74800607e-03,  4.42156021e-03,  5.68337750e-06,\n",
       "          1.18015369e-02,  7.55878201e-04, -4.61065565e-03,\n",
       "          1.33564765e-02,  1.67240600e-02,  2.83279148e-03,\n",
       "         -4.58894484e-04, -5.17239598e-03, -1.81476757e-02,\n",
       "         -4.64585582e-03,  2.46116869e-02,  1.30234490e-02,\n",
       "          3.76887180e-03,  2.27335672e-03,  1.06620458e-02,\n",
       "         -1.51985810e-02, -7.85663730e-03, -2.22936378e-02,\n",
       "         -5.71812305e-03, -3.76087219e-03,  1.88178467e-02,\n",
       "         -6.41605225e-03, -1.82852664e-02],\n",
       "        [ 5.38999757e-03, -4.96521676e-03, -9.64783625e-05,\n",
       "          1.77233832e-02,  2.43730323e-03,  5.30209035e-03,\n",
       "         -8.33090969e-03, -9.07450430e-03,  4.49659353e-03,\n",
       "          8.75459011e-03, -1.68591788e-04,  9.12139056e-03,\n",
       "          1.44209748e-03,  1.53449079e-02,  3.01131100e-03,\n",
       "         -3.74355730e-03, -5.66918422e-04, -5.66148853e-03,\n",
       "          1.10802004e-02,  3.56734051e-03, -5.83839922e-03,\n",
       "          1.62257267e-03,  4.46837939e-03, -8.06277773e-03,\n",
       "         -2.43373459e-02, -1.22036183e-03, -7.16973577e-03,\n",
       "         -1.46981221e-03,  1.14501604e-02,  4.03104979e-03,\n",
       "          5.01983517e-03, -2.76501983e-03,  1.79554657e-02,\n",
       "          4.51666679e-03,  2.25506910e-03,  1.12588419e-02,\n",
       "          7.61345728e-03,  2.39784162e-03, -1.02102027e-02,\n",
       "          7.73207692e-03,  1.42991424e-02, -3.28467270e-03,\n",
       "         -2.27837532e-02, -1.60649898e-02,  1.65821766e-02,\n",
       "         -7.78890803e-03, -2.49332538e-03, -7.51020133e-03,\n",
       "         -4.43706606e-03,  5.25613011e-03],\n",
       "        [ 1.85786113e-02,  1.18044536e-02, -6.32455685e-03,\n",
       "          7.56073041e-03,  3.62579328e-03,  7.81963638e-03,\n",
       "         -2.24573943e-05, -2.03883373e-02, -9.03434512e-03,\n",
       "         -1.35453216e-02,  3.76253812e-03,  8.61712147e-03,\n",
       "          5.69417113e-04,  9.61396705e-03, -1.30102798e-02,\n",
       "         -1.22616296e-02, -7.90180489e-03,  2.42888943e-03,\n",
       "          1.16905434e-02,  5.65844909e-03,  6.60991418e-03,\n",
       "          7.07746865e-03, -1.12794487e-02,  5.31540059e-03,\n",
       "         -7.74443371e-03, -1.08077494e-03, -1.78258375e-03,\n",
       "          1.43840377e-04, -8.46169397e-03, -6.09466037e-04,\n",
       "          3.86674072e-03, -3.51384700e-03,  6.07681589e-03,\n",
       "          7.56030932e-03,  8.66329930e-04, -1.99379267e-03,\n",
       "         -1.67812739e-02,  1.51661244e-03,  1.46574719e-02,\n",
       "          3.22656150e-03, -3.96129006e-03, -9.58132121e-03,\n",
       "         -4.72180653e-03, -1.24404259e-02, -4.36322562e-03,\n",
       "         -4.11754880e-03, -1.53571281e-02, -2.15784491e-02,\n",
       "         -6.36472297e-03,  1.17104061e-04],\n",
       "        [ 2.25177746e-04, -1.85583190e-03, -1.71922027e-02,\n",
       "         -2.78937153e-03,  1.11095696e-02, -7.61736208e-03,\n",
       "          4.40495639e-03, -3.33170977e-03, -4.69636298e-03,\n",
       "         -1.91748054e-02,  9.61768152e-03,  1.19855872e-02,\n",
       "          6.97961955e-03, -9.78690015e-04,  2.15426736e-02,\n",
       "         -1.16259615e-02, -3.98489361e-03,  1.02601888e-02,\n",
       "         -2.52984510e-02,  1.26353512e-02,  3.78261245e-04,\n",
       "         -7.23326188e-03, -1.14664913e-02,  3.66668444e-03,\n",
       "         -1.38105977e-02, -1.78587626e-03, -1.85279921e-02,\n",
       "          3.04608921e-04, -5.74486953e-03, -4.41094420e-03,\n",
       "         -3.06632674e-04, -1.23066649e-03, -2.16803130e-03,\n",
       "          7.10546257e-03, -1.30791669e-03, -2.01901339e-02,\n",
       "          9.45182312e-04, -4.07443495e-03, -5.77354096e-03,\n",
       "         -5.08882927e-03,  1.29117565e-02,  1.18014614e-03,\n",
       "          1.35251442e-02,  8.53038293e-03,  1.92186103e-02,\n",
       "          7.33222327e-03, -8.92017853e-03,  3.82465681e-03,\n",
       "         -7.29990187e-04, -1.09236244e-02],\n",
       "        [-7.09983471e-05, -3.47674302e-03,  6.58418072e-03,\n",
       "          4.09310753e-03,  6.63735570e-04, -2.84893695e-03,\n",
       "         -6.02555631e-03,  2.15037845e-03,  1.87161086e-02,\n",
       "         -1.16923613e-03, -2.26585756e-03, -2.37865886e-04,\n",
       "         -1.26831136e-02,  1.23787092e-02,  1.53313269e-02,\n",
       "          6.50055176e-03, -5.20292634e-03,  1.44344802e-02,\n",
       "          1.50965781e-02, -8.27735011e-03,  1.37899216e-02,\n",
       "         -7.28404672e-03,  1.75035867e-02, -2.01080030e-03,\n",
       "         -9.10416963e-04, -6.27337458e-03, -2.79159228e-03,\n",
       "          7.47859024e-03, -1.30483512e-02, -5.53087118e-03,\n",
       "          9.47638812e-03, -7.03412194e-03,  1.12099002e-02,\n",
       "          5.67656397e-03,  2.39025960e-02,  8.48513066e-03,\n",
       "          5.35659252e-04, -2.47955712e-02,  2.23242334e-03,\n",
       "         -7.74312869e-03, -1.00066657e-02,  3.78253024e-03,\n",
       "         -3.23908447e-03, -6.96053684e-03, -2.32760385e-03,\n",
       "          7.70578999e-03, -9.95841803e-03,  1.32643653e-02,\n",
       "         -3.53263636e-04, -2.50472072e-03],\n",
       "        [ 2.66693061e-03,  1.32620911e-02, -1.45757718e-02,\n",
       "          1.19649177e-02,  4.75898536e-03, -9.50370122e-03,\n",
       "         -1.10061985e-02,  1.23263152e-02, -2.37113172e-03,\n",
       "         -5.78257333e-03,  1.36458809e-02, -2.94479899e-03,\n",
       "         -1.65331322e-03, -1.25096154e-02, -4.57753846e-03,\n",
       "          2.60444947e-03, -2.79949875e-03, -3.53936516e-03,\n",
       "         -2.57029123e-03,  4.64672443e-05, -1.15990355e-02,\n",
       "          2.70111962e-03, -4.93599227e-03,  8.85529972e-03,\n",
       "          1.57148100e-03, -1.80386185e-02,  8.88638775e-03,\n",
       "         -4.64629996e-04,  1.15317627e-02,  8.75503276e-03,\n",
       "         -1.03514106e-02,  1.20925854e-02, -9.88075727e-03,\n",
       "          5.93019328e-03,  3.90479373e-03,  2.47193030e-03,\n",
       "          3.77548436e-03, -6.78352709e-03,  1.98840129e-03,\n",
       "         -8.81573203e-03, -3.81718214e-03, -4.61541242e-03,\n",
       "          1.24509333e-02, -6.27475675e-03, -4.55404234e-03,\n",
       "          4.39920300e-03,  2.19826574e-03, -1.31188666e-02,\n",
       "          2.61958858e-03, -9.34054348e-03],\n",
       "        [-2.27338915e-03, -1.32693552e-03, -1.21160275e-02,\n",
       "          6.77754102e-03, -6.85347837e-03, -3.29951584e-03,\n",
       "         -2.11940886e-03, -7.54143061e-03,  1.33540787e-02,\n",
       "         -7.86884674e-03,  4.32358685e-03, -1.54291487e-02,\n",
       "         -1.05179640e-02,  8.10424210e-03, -2.25508517e-03,\n",
       "          1.58122682e-04, -6.07817217e-03,  2.98233901e-03,\n",
       "         -2.37241965e-03,  6.89576784e-03,  1.32585466e-02,\n",
       "          1.23010288e-02, -8.74735143e-03, -7.29441178e-03,\n",
       "         -9.73789878e-03, -1.41835622e-03,  8.09321738e-03,\n",
       "          1.83979647e-02, -1.54508891e-02,  7.26432371e-03,\n",
       "         -9.85334582e-03,  9.21358860e-03,  2.21220654e-03,\n",
       "          7.49026845e-04,  1.41057487e-02,  1.82472000e-02,\n",
       "          7.18028224e-04,  1.03971143e-02, -9.86823291e-03,\n",
       "          7.48504655e-03, -6.90204540e-03,  2.16385028e-03,\n",
       "         -7.51866988e-04, -1.05916950e-02,  3.85093427e-03,\n",
       "         -1.01118283e-02, -9.24305572e-03,  4.23103090e-03,\n",
       "         -5.01137387e-03,  1.42768082e-02],\n",
       "        [-1.31679139e-03, -1.79718277e-02, -5.58879392e-03,\n",
       "          1.10060279e-02,  1.73686307e-02,  1.03393136e-02,\n",
       "          2.24428186e-02, -8.55194826e-03,  1.02283183e-03,\n",
       "          4.73819633e-03, -7.64505008e-03, -8.04581206e-04,\n",
       "          1.85441616e-02,  5.36779258e-04, -3.13074080e-03,\n",
       "         -1.32205994e-02, -4.84350646e-03,  5.08304149e-03,\n",
       "         -7.98483593e-03, -3.89923075e-03, -5.08969272e-04,\n",
       "          1.21602825e-03, -9.83904846e-04,  1.14221917e-02,\n",
       "          8.27701182e-03, -8.39737166e-04, -1.57998296e-02,\n",
       "         -1.08665649e-02,  1.50951473e-03, -2.66903464e-03,\n",
       "          3.31754251e-04,  6.10983846e-03, -5.94090642e-03,\n",
       "          2.72840428e-03,  3.42118692e-03,  6.65167804e-03,\n",
       "          1.00036565e-02, -9.24847572e-03,  3.48465124e-03,\n",
       "          1.61411081e-02, -3.03386995e-03, -2.19460159e-04,\n",
       "         -1.84980129e-03, -3.47905217e-03,  8.78162041e-03,\n",
       "         -1.00287411e-02, -1.00727376e-02,  5.12055057e-03,\n",
       "         -3.19162919e-03,  1.28269758e-03],\n",
       "        [ 8.71295267e-03,  1.96789850e-02, -1.26055646e-02,\n",
       "         -6.69557608e-03,  8.25464237e-03,  2.28327293e-02,\n",
       "          1.80879300e-02, -1.09293252e-02, -3.62448705e-03,\n",
       "         -2.88474934e-03, -1.88997332e-02, -8.95207104e-03,\n",
       "         -1.38624641e-02,  7.77347055e-03, -2.57538500e-02,\n",
       "         -2.16420024e-03, -4.12816357e-03,  1.25775099e-02,\n",
       "         -6.18413801e-03, -5.08954166e-03, -2.74256239e-03,\n",
       "          1.05726095e-02, -2.61409155e-02, -8.96229991e-04,\n",
       "         -7.77605317e-03,  2.72567263e-03,  5.85661427e-04,\n",
       "         -1.47985237e-02, -1.40788964e-02,  1.90652083e-02,\n",
       "          5.58649743e-04, -5.86190683e-03, -1.53484800e-03,\n",
       "         -1.01904593e-02, -1.68770818e-02, -1.86975437e-02,\n",
       "          3.30312501e-04, -1.10392527e-02,  3.68714369e-04,\n",
       "         -1.66798597e-02, -5.38015505e-03,  8.90727360e-03,\n",
       "          1.07769898e-02, -6.12405962e-03, -9.93984751e-04,\n",
       "          5.83498743e-03, -1.16421220e-03,  2.46781851e-03,\n",
       "          8.69934912e-03,  1.99274619e-02],\n",
       "        [ 1.01360860e-02,  2.91395432e-03, -1.77530235e-02,\n",
       "          7.39347333e-03, -1.03922650e-03,  1.26569311e-02,\n",
       "          1.19119634e-03,  9.41029549e-03, -3.73353815e-03,\n",
       "          1.40250483e-02, -1.07443488e-02, -8.61480959e-03,\n",
       "         -2.45708103e-03, -1.73083828e-02, -3.79569334e-03,\n",
       "          8.73466643e-03,  7.95612368e-03,  8.35496835e-04,\n",
       "          3.09855262e-03, -6.82851470e-04, -7.26708508e-03,\n",
       "         -1.26342299e-03, -1.12105823e-03, -3.81167984e-03,\n",
       "         -4.11719431e-03,  6.61388152e-03,  1.25772947e-03,\n",
       "          8.16386315e-03, -4.39358321e-03,  6.30648414e-03,\n",
       "          1.69824771e-02,  6.26828312e-03, -1.78180448e-02,\n",
       "         -1.01504859e-02,  5.14542430e-03, -2.08736717e-02,\n",
       "          2.47895992e-04,  3.96857972e-03, -2.19897558e-02,\n",
       "         -2.50934847e-03,  2.20707549e-02, -1.02122249e-02,\n",
       "         -1.61085943e-02, -4.80393718e-03,  5.10869868e-03,\n",
       "          1.14958168e-02, -1.51803426e-02,  1.60057330e-03,\n",
       "          1.28662960e-03,  7.92293807e-03],\n",
       "        [-1.53634148e-02,  1.15287002e-03,  1.54977380e-02,\n",
       "         -4.80381968e-04,  1.62207335e-03,  1.13358110e-02,\n",
       "         -3.03180069e-03,  4.11989204e-04,  1.88796678e-03,\n",
       "          1.71626513e-02,  1.82215063e-02, -5.50474312e-03,\n",
       "         -1.41827577e-02,  1.82741914e-02, -1.20363790e-04,\n",
       "          2.01249185e-03, -2.31338504e-03,  1.45049592e-03,\n",
       "          3.75510431e-03,  5.92603530e-03,  1.17340106e-02,\n",
       "          1.32065231e-02,  6.46439595e-03,  1.26663329e-02,\n",
       "         -7.10181496e-03, -5.33071516e-03,  9.40599645e-03,\n",
       "         -3.33744941e-03,  9.67880806e-03, -8.62498644e-03,\n",
       "         -5.62485569e-03, -4.59282249e-03, -1.08800533e-02,\n",
       "         -7.98304733e-04,  1.55354803e-02,  4.90218213e-03,\n",
       "          6.96487980e-03, -6.56099045e-03, -6.25428024e-03,\n",
       "         -1.01093544e-02,  6.19425246e-03, -2.27273485e-03,\n",
       "         -1.51100861e-02, -6.21985355e-03, -1.67225042e-03,\n",
       "          7.51748083e-03,  1.26004999e-02, -1.32290204e-03,\n",
       "          7.79496407e-04, -7.50361508e-03],\n",
       "        [ 1.94746505e-02, -5.32505973e-03,  5.19688620e-03,\n",
       "          2.50332060e-02, -8.07716757e-07,  5.76842173e-03,\n",
       "          8.94249995e-03,  1.48262809e-02, -6.80407584e-03,\n",
       "         -1.15245255e-02, -1.49370449e-02,  1.00862714e-02,\n",
       "          5.03569621e-03,  3.18466152e-03,  3.36731916e-03,\n",
       "         -2.38558497e-03,  1.90938485e-02,  7.62873433e-03,\n",
       "          6.21900278e-03,  7.85745274e-03,  4.73634673e-03,\n",
       "         -1.77133874e-02, -1.17675216e-02,  3.28926511e-03,\n",
       "          1.96866545e-02, -7.94430077e-03, -7.42802593e-03,\n",
       "         -9.63224129e-03, -6.05254871e-03,  1.22522455e-02,\n",
       "         -1.28571895e-02,  7.26697363e-03,  6.71689161e-03,\n",
       "          1.54344329e-02,  4.20323850e-03,  1.73887671e-02,\n",
       "         -1.24676188e-02, -9.16721572e-03,  8.62225025e-03,\n",
       "          1.19660604e-02,  1.39818433e-02, -4.68544862e-03,\n",
       "          3.05668985e-03, -3.47512661e-03,  7.89996833e-03,\n",
       "         -6.46476882e-03, -3.49565134e-03, -1.36252984e-02,\n",
       "         -4.69250777e-03, -7.13547102e-03],\n",
       "        [-7.42994636e-03,  5.14954570e-03,  6.67122344e-04,\n",
       "         -3.68447661e-04, -8.87933778e-03,  7.75889243e-03,\n",
       "         -2.14435623e-03, -9.26118792e-03,  4.24631938e-03,\n",
       "          2.41209351e-03,  1.38912491e-02, -6.25706565e-03,\n",
       "          7.68192151e-03,  1.00199921e-02, -1.07106121e-02,\n",
       "         -4.83953799e-03,  9.66246449e-03,  3.72684830e-03,\n",
       "         -1.08409709e-02,  4.83824545e-03, -4.13087205e-03,\n",
       "         -3.98638624e-03, -1.05607082e-02, -6.54556693e-03,\n",
       "          9.28218774e-04,  7.03433107e-03, -4.81364245e-03,\n",
       "          4.46731270e-03,  6.10982956e-03, -1.59734332e-03,\n",
       "         -2.64440810e-03, -1.95923474e-02,  3.89786235e-03,\n",
       "          9.92839972e-03, -9.56246976e-03,  5.94955329e-03,\n",
       "          5.88408001e-04, -3.70459124e-04, -7.92279848e-03,\n",
       "          7.44347550e-03,  8.93596139e-03, -6.92619435e-03,\n",
       "          1.31581005e-02, -1.13754008e-02, -3.97159454e-03,\n",
       "         -6.51463366e-03,  8.75452206e-03,  5.72108762e-03,\n",
       "          7.42997152e-03,  1.80637251e-03],\n",
       "        [ 1.11067997e-02,  1.00682660e-02, -8.87177434e-03,\n",
       "         -1.04001926e-02,  5.25048117e-03, -4.64492144e-03,\n",
       "         -2.03046760e-02, -8.42847960e-04,  1.04343932e-02,\n",
       "         -4.51784961e-03,  2.09942391e-03,  3.66097180e-03,\n",
       "         -4.70818904e-03,  2.02894237e-02,  1.78337094e-02,\n",
       "          2.65063968e-03, -3.17125604e-03, -8.07592713e-03,\n",
       "          6.54320576e-03,  3.68606003e-03, -3.54106192e-03,\n",
       "          8.66587574e-03,  6.77398266e-03,  4.63622270e-03,\n",
       "          8.53950333e-03,  3.26529669e-03, -6.24159760e-03,\n",
       "         -4.49679476e-03,  9.90035828e-03,  9.91149424e-03,\n",
       "         -4.62901007e-03,  6.00698046e-03, -1.31837502e-02,\n",
       "         -6.89787017e-03,  1.36488654e-03,  4.49861187e-03,\n",
       "          8.83544113e-03,  1.74433505e-02,  1.92133881e-02,\n",
       "         -2.83072566e-03, -1.74095914e-04, -5.71251997e-04,\n",
       "         -2.09823837e-02,  5.25592922e-03,  1.19182650e-02,\n",
       "         -1.51646329e-02, -1.23835180e-02,  1.29321599e-02,\n",
       "         -5.68710106e-03, -1.66055123e-02],\n",
       "        [-5.86915418e-03,  7.46191582e-03,  1.84561917e-02,\n",
       "          3.49804688e-03,  1.01937321e-02,  4.44570141e-03,\n",
       "          2.84860560e-03, -1.95745872e-03,  8.48285297e-03,\n",
       "          1.20970121e-03,  5.16196020e-03, -5.55949450e-03,\n",
       "         -1.24439812e-02, -1.19364327e-02, -5.87159132e-04,\n",
       "         -1.07021752e-02, -3.29309894e-03, -1.35341564e-02,\n",
       "          3.63655021e-03,  7.50464500e-03, -1.16609020e-02,\n",
       "         -9.42654513e-04, -1.81644783e-02, -1.30031284e-02,\n",
       "         -3.79380591e-03, -1.20199032e-02, -1.29624360e-02,\n",
       "          4.54158569e-04,  7.23756165e-03, -5.98171654e-03,\n",
       "         -5.50358853e-03,  1.52032690e-03, -1.02582164e-02,\n",
       "          9.50109543e-03,  1.40444190e-02, -1.02223075e-02,\n",
       "         -3.51623918e-03, -4.96617087e-03,  3.88324878e-03,\n",
       "          1.01370481e-03, -6.20710697e-03,  2.83450185e-06,\n",
       "          8.72587821e-04,  4.94943816e-03, -6.92651472e-03,\n",
       "         -5.31314286e-04, -1.55145777e-03, -3.25239997e-04,\n",
       "         -1.27965474e-02,  9.74592172e-03],\n",
       "        [ 3.49235831e-03,  2.65602199e-03,  9.14309439e-03,\n",
       "          1.34710094e-02, -1.17473402e-02, -1.19270533e-02,\n",
       "          1.36501493e-02,  2.52236712e-02, -9.96583368e-03,\n",
       "         -2.26477006e-03, -5.70257695e-03,  3.15273306e-03,\n",
       "         -7.94599429e-03, -3.05795576e-03,  1.01185606e-02,\n",
       "         -1.30821725e-03,  1.70300642e-02, -1.61169595e-02,\n",
       "         -1.70809879e-02,  1.02411589e-02,  1.06374309e-02,\n",
       "         -5.07886284e-03,  1.17353728e-02,  3.91691508e-03,\n",
       "         -1.30863946e-03, -3.08876667e-03, -9.47919580e-03,\n",
       "         -8.49242501e-03, -9.30868013e-03,  6.54512429e-03,\n",
       "          1.17595506e-02,  9.15168905e-03,  3.41361736e-03,\n",
       "          4.22924941e-03, -1.11320792e-02,  2.29145933e-03,\n",
       "          1.12393950e-02, -6.49948715e-03, -2.87471715e-03,\n",
       "         -4.25275439e-03,  5.96135099e-03,  1.48655855e-02,\n",
       "          1.35208179e-02, -1.77243664e-02, -1.31499690e-02,\n",
       "          1.39018768e-03, -4.62134677e-03, -5.33493133e-03,\n",
       "         -2.76505704e-03, -9.62303894e-03],\n",
       "        [ 1.37093603e-03,  2.45584100e-03, -1.44460984e-02,\n",
       "          3.31593188e-03, -8.88453184e-03,  1.05414644e-02,\n",
       "          5.84010081e-03,  3.21312013e-04,  8.14320201e-03,\n",
       "         -5.79028122e-03,  4.16374478e-03, -7.04219895e-03,\n",
       "         -3.92065361e-03,  1.07197011e-02,  2.48639743e-03,\n",
       "         -1.71407629e-02,  6.68143458e-03, -1.67916030e-02,\n",
       "          4.49878830e-03,  3.52822631e-03,  8.97034603e-03,\n",
       "          3.83016937e-03, -4.76878978e-03,  3.48674041e-03,\n",
       "         -1.42119089e-02, -7.94576275e-03,  1.94819664e-03,\n",
       "          2.52312156e-03,  8.29058574e-04,  1.58879747e-02,\n",
       "          1.77592880e-03, -7.20143731e-03,  4.66210405e-03,\n",
       "          1.58848463e-02,  8.76452106e-04, -2.03692475e-03,\n",
       "          1.76450066e-02,  1.42944587e-02,  7.29757154e-03,\n",
       "          5.98374691e-03, -1.91939525e-04,  8.13115464e-03,\n",
       "          8.34754538e-03,  2.71803378e-03,  1.61371963e-02,\n",
       "         -2.29378861e-03,  1.74248199e-02, -9.04946267e-03,\n",
       "         -9.19050799e-03,  6.15493937e-03]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[-0.0008917 , -0.01730931, -0.02127559, -0.00430297,  0.00477849,\n",
       "          0.00248241,  0.00264023,  0.02440589, -0.01149968,  0.00397202,\n",
       "         -0.01520602,  0.01641465, -0.01360001,  0.01384659,  0.00080911,\n",
       "          0.00653652, -0.00185168, -0.01218639, -0.00582024, -0.00395826],\n",
       "        [ 0.01092783, -0.0203055 , -0.00219469, -0.00039181, -0.00383784,\n",
       "          0.01222893,  0.00424933,  0.00189894,  0.01372616,  0.00601972,\n",
       "         -0.02067273,  0.01283016,  0.00152977,  0.01878854,  0.01962231,\n",
       "         -0.00476724, -0.01036923,  0.0081747 , -0.00772787,  0.01131077],\n",
       "        [ 0.01054305, -0.02187281,  0.01502779,  0.03066535, -0.00466857,\n",
       "         -0.00589566,  0.00512267, -0.00385809, -0.00926645, -0.01122462,\n",
       "         -0.00996842,  0.0146488 , -0.0001662 , -0.0162016 , -0.01558258,\n",
       "          0.00429318,  0.00722794, -0.00952616, -0.00652736,  0.00749273],\n",
       "        [ 0.00976197,  0.00120762, -0.00779434, -0.00357263, -0.00530131,\n",
       "         -0.01155995, -0.00116583, -0.00545395, -0.01362137,  0.00929047,\n",
       "         -0.00268845, -0.00873244, -0.01142686, -0.01171704,  0.00747714,\n",
       "         -0.00193787, -0.00403943, -0.00072738, -0.01210508, -0.01580355],\n",
       "        [ 0.01197171, -0.00460657, -0.00220873, -0.00604807, -0.00237288,\n",
       "         -0.01000237, -0.01470115,  0.0097538 , -0.01878958,  0.01392506,\n",
       "          0.00506204, -0.00417089, -0.00515329, -0.00683195, -0.03223648,\n",
       "          0.00452149, -0.00012459, -0.01304107, -0.00287925,  0.0054647 ]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[-0.0058556 ,  0.00611925,  0.02757497,  0.00037895, -0.00361311]]),\n",
       " 'b4': array([[0.]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj1 = RNA()\n",
    "obj1.inicializa_parametros([30,50,20,5,1])\n",
    "obj1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b167b562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametros = obj1.parameters\n",
    "parametros['W1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abe0bb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0ffcc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6483278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({'1':1, '2':2, '3':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf00b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01aa98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
